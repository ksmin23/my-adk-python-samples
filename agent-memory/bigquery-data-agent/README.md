# BigQuery Data Agent with Agent Engine Memory Bank

A self-learning BigQuery agent that stores and retrieves successful SQL queries using the Agent Engine Memory Bank. Queries can be shared across users within a team or kept private.

## Features

- **Natural Language to SQL**: Convert user questions to BigQuery SQL.
- **Self-Learning Memory**: Automatically searches past queries before generating new ones.
- **Scoped Sharing**: Save queries to personal (`user`) or shared (`team`) memory.
- **Enhanced Searchability**: Each saved query includes title, description, and original question for accurate retrieval.
- **Built-in Memory Tools**:
    - `PreloadMemoryTool`: Automatically retrieves relevant memories into system instructions.
    - `LoadMemoryTool`: Allows the agent to selectively load specific memories when needed.

## Prerequisites

- Python 3.10+
- Google Cloud Project with:
  - BigQuery API enabled
  - Vertex AI API enabled (for Agent Engine Memory Bank)
- ADK installed (`pip install google-adk`)
- Vertex AI SDK (`pip install google-cloud-aiplatform`)

## Setup

### 1. Configure Environment

Create a `.env` file in `bigquery_data_agent/`:

```bash
# Google Cloud Configuration
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_LOCATION=us-central1

# BigQuery Configuration
BIGQUERY_DATASET=your_dataset_name

# Agent Configuration
AGENT_MODEL=gemini-2.5-flash
```

### 2. Create Memory Bank

Before running the agent, create an Agent Engine with Memory Bank configuration:

```bash
# Using defaults from .env
python utils/setup_memory_bank.py

# Or providing arguments explicitly
python utils/setup_memory_bank.py --project=your-project-id --location=us-central1
```

This creates the necessary **Reasoning Engine** infrastructure on Vertex AI with custom memory topics. 
The setup script ensures that the engine is provisioned with a display name matching the agent name (`bigquery_data_agent`). 

Once provisioned, the ADK framework automatically resolves and connects to this memory bank at runtime based on the matching name, so you don't need to manually manage the Engine ID in your `.env` file.

### 3. Run the Agent

```bash
# From this directory
adk web
```

Or programmatically:

```python
from bigquery_data_agent.agent import root_agent
# ... use with Runner
```

## Test Scenarios

### Scenario 1: Save a User-Scope Query

```
User: "ì›”ë³„ ë§¤ì¶œ í•©ê³„ë¥¼ ë³´ì—¬ì¤˜"
Agent: (executes query and returns results)
User: "ì´ ì¿¼ë¦¬ë¥¼ ì €ì¥í•´ì¤˜. ì œëª©ì€ 'ì›”ë³„ ë§¤ì¶œ í•©ê³„'ë¡œ í•´ì¤˜."
Agent: "Query 'ì›”ë³„ ë§¤ì¶œ í•©ê³„' saved to user memory."
```

### Scenario 2: Save a Team-Scope Query

```
User: "Top 10 ê³ ê° ëª©ë¡ì„ íŒ€ ê³µìœ ë¡œ ì €ì¥í•´ì¤˜"
Agent: "Query 'Top 10 Customers' saved to team memory."
```

### Scenario 3: Search Existing Queries

```
User: "ë§¤ì¶œ ê´€ë ¨ ì¿¼ë¦¬ ì°¾ì•„ì¤˜"
Agent: (searches user and team memories)
       "Found 2 matches:
        1. [user] ì›”ë³„ ë§¤ì¶œ í•©ê³„ - ìµœê·¼ 12ê°œì›”ì˜ ì›”ë³„ ë§¤ì¶œ í•©ê³„
        2. [team] ì¼ë³„ ë§¤ì¶œ ë¦¬í¬íŠ¸ - ì¼ë³„ ë§¤ì¶œ í˜„í™© ì¡°íšŒ"
```

### Scenario 4: Scope Isolation Test

```
# User A saves to user scope
User A: "ì´ ì¿¼ë¦¬ë¥¼ ë‚´ ê°œì¸ ì €ì¥ì†Œì— ì €ì¥í•´ì¤˜"

# User B should NOT see User A's personal queries
User B: "ë‚´ ì €ì¥ëœ ì¿¼ë¦¬ ê²€ìƒ‰í•´ì¤˜"
Agent: (returns only User B's personal queries)
```

## Project Structure

```
bigquery-data-agent/
â”œâ”€â”€ README.md
â”œâ”€â”€ utils/                   # Utility and configuration scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory_bank_customization.py # Memory Bank customization config
â”‚   â””â”€â”€ setup_memory_bank.py  # CLI script to create Agent Engine
â””â”€â”€ bigquery_data_agent/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ .env.example          # Environment configuration template
    â”œâ”€â”€ agent.py              # LlmAgent definition
    â”œâ”€â”€ prompts.py            # Agent instructions
    â””â”€â”€ tools.py              # BigQuery and Memory tools
```

## Memory Storage Format

Queries are stored with the following structure:

```
Title: ì›”ë³„ ë§¤ì¶œ í•©ê³„
Description: ìµœê·¼ 12ê°œì›”ì˜ ì›”ë³„ ë§¤ì¶œ í•©ê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
NL Query: ì›”ë³„ ë§¤ì¶œ í•©ê³„ë¥¼ ë³´ì—¬ì¤˜
SQL: SELECT FORMAT_DATE('%Y-%m', order_date) AS month, SUM(amount) AS total_sales ...
```

## Scope Types

| Scope | Storage | Visibility |
|-------|---------|------------|
| `user` | user_id | Personal only |
| `team` | team_id | All team members |
| `global` | (search only) | Searches both user and team |


## References

- ğŸ““ [Get started with Memory Bank on ADK](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank_on_adk.ipynb)
- ğŸ“ [Self Improving Text2Sql Agent with Dynamic Context and Continuous Learning (2025-12-15)](https://www.ashpreetbedi.com/articles/sql-agent): A self-improving Text-to-SQL agent using dynamic context and "poor-man's continuous learning".
- :octocat: [Dash](https://github.com/agno-agi/dash): Dash is a **self-learning data agent** that grounds its answers in **6 layers of context** and improves with every run. Inspired by [OpenAI's in-house data agent](https://openai.com/index/inside-our-in-house-data-agent/).
- ğŸ“ [OpenAI's in-house data agent (2026-01-29)](https://openai.com/index/inside-our-in-house-data-agent/)